{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d62d40fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import random\n",
    "import math\n",
    "from collections import Counter\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3cfb1a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('./tasksv11/en/qa1_single-supporting-fact_train.txt', 'r')\n",
    "raw = f.readlines()\n",
    "f.close()\n",
    "\n",
    "tokens = list()\n",
    "for line in raw[0:1000]:\n",
    "    tokens.append(line.lower().replace(\"\\n\", \"\").split(\" \")[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a5ee7dc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['mary', 'moved', 'to', 'the', 'bathroom.'], ['john', 'went', 'to', 'the', 'hallway.'], ['where', 'is', 'mary?', '\\tbathroom\\t1']]\n"
     ]
    }
   ],
   "source": [
    "print(tokens[0:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "df6028cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = set()\n",
    "for sent in tokens:\n",
    "    for word in sent:\n",
    "        vocab.add(word)\n",
    "\n",
    "vocab = list(vocab)\n",
    "\n",
    "word2index = {}\n",
    "for i, word in enumerate(vocab):\n",
    "    word2index[word] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bdb4f5e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def words2indices(sentence):\n",
    "    idx = list()\n",
    "    for word in sentence:\n",
    "        idx.append(word2index[word])\n",
    "    return idx\n",
    "\n",
    "def softmax(x):\n",
    "    e_x = np.exp(x - np.max(x))\n",
    "    return e_x / e_x.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "70cb542b",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "embed_size = 10\n",
    "embed = (np.random.rand(len(vocab), embed_size) - 0.5) * 0.1\n",
    "recurrent = np.eye(embed_size)\n",
    "start = np.zeros(embed_size)\n",
    "decoder = (np.random.rand(embed_size, len(vocab)) - 0.5) * 0.1\n",
    "one_hot = np.eye(len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "79de55be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(sent):\n",
    "    layers = list()\n",
    "    layer = {}\n",
    "    layer['hidden'] = start\n",
    "    layers.append(layer)\n",
    "    \n",
    "    loss = 0\n",
    "    \n",
    "    preds = list()\n",
    "    for target_i in range(len(sent)):\n",
    "        layer = {}\n",
    "        layer['pred'] = softmax(layers[-1]['hidden'].dot(decoder))\n",
    "        loss += -np.log(layer['pred'][sent[target_i]])\n",
    "        layer['hidden'] = layers[-1]['hidden'].dot(recurrent) + \\\n",
    "                          embed[sent[target_i]]\n",
    "        layers.append(layer)\n",
    "    return layers, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d47406c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "perplexity: 81.9696433994313\n",
      "perplexity: 81.79598723570629\n",
      "perplexity: 81.52450780454359\n",
      "perplexity: 80.99586521548164\n",
      "perplexity: 79.86900330313478\n",
      "perplexity: 77.20048304819166\n",
      "perplexity: 69.07372820534131\n",
      "perplexity: 40.321888708580516\n",
      "perplexity: 24.203354611386363\n",
      "perplexity: 19.67468473568944\n",
      "perplexity: 18.476482241471874\n",
      "perplexity: 17.283464549218092\n",
      "perplexity: 15.544117112046044\n",
      "perplexity: 12.818550057299666\n",
      "perplexity: 9.495359337252145\n",
      "perplexity: 7.433730869415573\n",
      "perplexity: 6.359237160084933\n",
      "perplexity: 5.66728613404888\n",
      "perplexity: 5.256542093796923\n",
      "perplexity: 4.977988762691367\n",
      "perplexity: 4.794043667543352\n",
      "perplexity: 4.687249891380066\n",
      "perplexity: 4.628527717844853\n",
      "perplexity: 4.574922316767583\n",
      "perplexity: 4.505928107713292\n",
      "perplexity: 4.421426749687874\n",
      "perplexity: 4.327162103272879\n",
      "perplexity: 4.228574421200357\n",
      "perplexity: 4.1291457968397545\n",
      "perplexity: 4.023536289952996\n"
     ]
    }
   ],
   "source": [
    "for iter in range(30000):\n",
    "    alpha = 0.001\n",
    "    sent = words2indices(tokens[iter%len(tokens)][1:])\n",
    "    layers, loss = predict(sent)\n",
    "    for layer_idx in reversed(range(len(layers))):\n",
    "        layer = layers[layer_idx]\n",
    "        target = sent[layer_idx-1]\n",
    "        \n",
    "        if(layer_idx > 0):\n",
    "            layer['output_delta'] = layer['pred'] - one_hot[target]\n",
    "            new_hidden_delta = layer['output_delta'].dot(decoder.transpose())\n",
    "            if(layer_idx == len(layers)-1):\n",
    "                layer['hidden_delta'] = new_hidden_delta\n",
    "            else:\n",
    "                layer['hidden_delta'] = new_hidden_delta + \\\n",
    "                                        layers[layer_idx+1]['hidden_delta'].dot(recurrent.transpose())\n",
    "        else:\n",
    "            layer['hidden_delta'] = layers[layer_idx+1]['hidden_delta'].dot(recurrent.transpose())\n",
    "        \n",
    "    start -= layers[0]['hidden_delta'] * alpha / float(len(sent))\n",
    "    for layer_idx, layer in enumerate(layers[1:]):\n",
    "        decoder -= np.outer(layers[layer_idx]['hidden'],\n",
    "                            layer['output_delta']) * alpha / float(len(sent))\n",
    "        embed_idx = sent[layer_idx]\n",
    "        embed[embed_idx] -= layers[layer_idx]['hidden_delta'] * \\\n",
    "                             alpha / float(len(sent))\n",
    "        recurrent -= np.outer(layers[layer_idx]['hidden'],\n",
    "                              layer['hidden_delta']) * alpha /float(len(sent))\n",
    "    if(iter % 1000 == 0):\n",
    "        print(\"perplexity: \" + str(np.exp(loss/len(sent))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c099cf15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sandra', 'moved', 'to', 'the', 'garden.']\n",
      "Prev Input:sandra      True:moved          Pred:is\n",
      "Prev Input:moved       True:to             Pred:to\n",
      "Prev Input:to          True:the            Pred:the\n",
      "Prev Input:the         True:garden.        Pred:bedroom.\n"
     ]
    }
   ],
   "source": [
    "sent_index = 4\n",
    "l, _ = predict(words2indices(tokens[sent_index]))\n",
    "print(tokens[sent_index])\n",
    "\n",
    "for i, each_layer in enumerate(l[1:-1]):\n",
    "    input = tokens[sent_index][i]\n",
    "    true = tokens[sent_index][i+1]\n",
    "    pred = vocab[each_layer['pred'].argmax()]\n",
    "    print(\"Prev Input:\" + input + (' '*(12 - len(input))) + \\\n",
    "          \"True:\" + true + (' '*(15 - len(true))) + \"Pred:\" + pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c600ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
